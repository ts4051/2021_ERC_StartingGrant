\documentclass[a4paper,11pt]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[pages=some,scale=1,angle=0,opacity=1]{background}
\usepackage{bm}
\usepackage{caption}
\usepackage{colortbl}
\usepackage{enumitem}
\usepackage{eurosym}
\usepackage{fancyhdr}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{lineno}
\usepackage{mathtools}
\usepackage{multicol}
\usepackage{multirow}
\usepackage{parskip}
\usepackage{setspace}
\usepackage{ragged2e}
\usepackage{subcaption}
\usepackage{tabularx}
\usepackage{tabulary}
\usepackage{titlesec}
\usepackage[T1]{fontenc}
\usepackage{times}
\usepackage{url}
\usepackage{wallpaper}
\usepackage{wrapfig}
\usepackage{xcolor}

\usepackage[colorinlistoftodos]{todonotes}

\usepackage{array}
\newcolumntype{C}[1]{>{\centering\arraybackslash}p{#1}}

\newcommand\BackImage[2][scale=1]{%
\BgThispage
\backgroundsetup{
  contents={\includegraphics[#1]{#2}}
  }
}

% Shrink the spacing between references in the bibliography
%\usepackage{etoolbox}
%\patchcmd\thebibliography
% {\labelsep}
% {\labelsep\itemsep=-8pt\relax}
% {}
% {\typeout{Couldn't patch the command}}
 %%% End of code to add %%%

\bibliographystyle{h-physrev}

\renewcommand{\thesection}{\Alph{section}}

\newcounter{bar}
\newcommand{\taskcounter}{%
        \stepcounter{bar}%
        \thebar}

\setlist[itemize]{itemsep=-4pt, topsep=-2pt}

\usepackage{hyperref}
% \usepackage{cleveref}

\hypersetup{ colorlinks=false,
		     linkcolor=green,
		     urlbordercolor=blue,
		     pdfborderstyle={/S/U/W 1}}

\geometry{tmargin=2.5cm, bmargin=1.5cm, lmargin=2.cm, rmargin=2.cm}

\singlespacing
%\setstretch{1.035}

%\linenumbers

\setlength{\headheight}{15pt} 

\footskip=22pt
\headsep=18pt

\titlespacing*{\section}{0pt}{1pt}{1pt}
\titlespacing*{\subsection}{0pt}{1pt}{1pt}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\renewcommand{\headrulewidth}{0pt}

% \pagestyle{fancyplain}

% \lhead[\it Koskinen]{\it Koskinen}
% \chead{B2 - Scientific Proposal}
% \rhead{NuUnity}

\centerline{\huge ERC Starting Grant 2021}
\centerline{\huge Part B2}
\centerline{\Large }
\centerline{\huge \textbf{A wrinkle in space-time}}
\centerline{\Large \textbf{(SpWrinkle)}}

\vspace{0.5cm}
%
%\ThisURCornerWallPaper{0.2}{plots/NeutrinoTriangleSimple.pdf}
%
%\makebox[50pt][l]{%
 % \raisebox{-\totalheight}[0pt][0pt]{%
  %  \includegraphics[width=4in]{plots/NeutrinoTriangleSimple.pdf}}}%
  
% \BackImage[width=0.07\textwidth]{plots/NeutrinoTriangleSimple.pdf}

% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------

% \section{Notes}
% \vspace{0.1 cm}

% \begin{itemize}
%     \item Comment that the whole project is risky given the potential for QG signals to be unmeasurably tiny (e.g. fr from guaranteed results), but the reward for  detection is huge and the fact I can rue out some models is a rare opportunity
%     \item Extra collaborative stuff like run workshops, collaborate with KM3NeT, open sourec signal code, etc
%     \item Synergy between event generator and (anti)neutrino separation, since both need detailed understanding of inelasticity
% \end{itemize}

% \textbf{14 PAGE LIMIT}

% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------

% \todo{Generally need more specifics and more focus on experts}
% \todo{Need to either remove bold highlighting or add it to sections where it is missing}

\section{State-of-the-art and Objectives}
\vspace{0.1 cm}

% \textbf{From instructions:} State-of-the-art and objectives. Specify the proposal objectives in the context of the state
% of the art in the research field. It should be clear how and why the proposed work is important for
% the field, and what impact it will have if successful, such as how it may open up new horizons or
% opportunities for science, technology or scholarship. Specify any particularly challenging or
% unconventional aspects of the proposal, including multi- or inter-disciplinary aspects.

\subsection{Introduction}

Despite every other force in Nature being successfully described by quantum mechanics and decades of theoretical efforts there is currently no quantum theory of gravity. A major contributing factor to this impasse is the paucity of meaningful experimental constraints to guide theory, a consequence of the astounding weakness of gravity compared to the other forces. In fact, gravity is only expected to become strong in particle interactions at energies 15 orders of magnitude higher than can be achieved in the most powerful particle colliders.

Even considering gravity's weakness as a fundamental force, there is hope to confront this glaring theoretical void in our understanding of the Universe. Neutrinos are barely affected by the other forces of Nature and thus can travel vast distances, allowing even the very weak gravitational effects expected in a quantum theory of gravity to accumulate into potentially measurable signals. Furthermore, the bombardment of the Earth by cosmic rays from violent astrophysical sources produces an atmospheric neutrino flux with energies far exceeding those from man-made accelerators, allowing the suppression of the effects of quantum gravity to be at least partially overcome.

\begin{wrapfigure}{R}{0.45\textwidth} %this figure will be at the right
    \centering
		\vspace{-7pt}
		\includegraphics[width=1.\linewidth]{images/paper_plots_toy_model_net_decoh.pdf}
		\caption{Toy model example of individual neutrinos propagating in a fluctuating environment. The neutrinos become increasingly out of phase, resulting in neutrino decoherence and the damping of the average oscillation probability of the ensemble.}
		\vspace{-5pt}
		\label{fig:decoherence}
\end{wrapfigure}

A quantum theory of gravity is expected to fundamentally alter the structure of space-time at microscopic scales, resulting in an uncertain/fluctuating space-time geometry that would degrade the quantum superposition phenomenon of neutrino oscillations in a process known as neutrino decoherence. Additionally, symmetries fundamental to our current understanding of of particle physics such as $CPT$ (Charge-Parity-Time) symmetry may be violated if gravity is a quantum force, producing differences in neutrino oscillation effects between neutrinos and their antimatter counterparts. 

My scientific vision is to perform the world's most sensitive searches for these signatures of quantum gravity with neutrinos, some of which will be world-firsts based on theoretical models I have developed. To do so I will exploit the vast flux of high energy neutrinos produced in the Earth's atmosphere, observed using the world's largest and most sensitive neutrino telescope the IceCube neutrino observatory at the South Pole, creating a state-of-the-art new data sample with unprecedented statistics and range of neutrino energies, and pioneering the first use of (anti)neutrino discrimination methods in neutrino telescope oscillation measurements. Crucially, I have demonstrated that these searches are capable of detecting the predicted size of these quantum gravity effects in a number of scenarios, giving the realistic possibility of the first experimental detection of the signs of quantum gravity, which would be a truly revolutionary result. These results will also directly confront the question of why the Universe is dominated by matter rather than antimatter, one of the greatest open questions in physics.

I have developed a number models of neutrino decoherence resulting from quantum gravity that I will test in this project, enabling the inference of the underlying space-time properties from experimental neutrino observations for the first time, and have a growing reputation in the theoretical community (recently being invited to co-author an international review of the field). As the leader of the recent generation of world-class IceCube neutrino oscillation measurements (with a team of 13 physicists from 7 institutes in Europe and the US) I have experience leading a major international research project and unparalleled expertise in measuring neutrino oscillations with IceCube, and play a prominent role in the IceCube detector upgrade that this project will exploit. My scientific leadership skills have been recognised by the IceCube collaboration, where I hold the roles of \textit{IceCube Upgrade simulation manager} (I am the named responsible person to the US National Science Foundation for delivering all simulations for this \$37 million project) and \textit{IceCube oscillation physics co-convener}. My combination of experimental, phenomenological and leadership expertise make me uniquely capable to tackle these ambitious measurements. \\

%\textbf{normally considered beyond the reach of experiment

\subsection{Quantum gravity}

% \begin{wrapfigure}{R}{0.43\textwidth} %this figure will be at the right
%     \centering
%         % \vspace{-9pt}
%         \includegraphics[trim=0.0cm 0.4cm 0.cm 0.5cm, clip=true, width=1.\linewidth]{images/paper_plots_coherence_length_vs_energy_planck.pdf}
% 		\caption{Distance at which decoherence due to Planck-scale physics is expected to become significant, for a variety of power-law, $E^n$, energy dependencies~\cite{PhysRevD.102.115003}. Sensitivity can be achieved with terrestrial neutrino sources in some scenarios, whilst astrophysical distances are required in others.}
% % 		\vspace{-7pt}
% 		\label{fig:planck_scale_coherence_length}
% \end{wrapfigure}

% \begin{wrapfigure}{R}{0.5\textwidth} %this figure will be at the right
%     \centering
% 		\includegraphics[width=1.\linewidth]{images/quantum_foam_2.png}
% 		\caption{An artists impression of the fluctuating nature of space-time at tiny distance scales, as expected in a quantum theory of gravity.}
% 		\vspace{-7pt}
% 		\label{fig:spacetime_foam}
% \end{wrapfigure}

Einstein's theory of general relativity (GR) has been remarkably successful at describing the influence of gravity at macroscopic scales, but breaks down when applied to dense, compact systems such as black holes and the early Universe. GR therefore cannot be the full story, and a quantum explanation for gravity must exist. The effects of quantum gravity are typically expected to be strong at the \textit{Planck scale}, meaning colossal energies of $10^{19}$ GeV or minuscule distances of $10^{-35}$ m, and its effects are likely suppressed at the energy and distance scales we can experimentally probe and have thus far evaded detection.

% \todo{More about why GR and QM are incompatible? or too basic?}

Although we do not have a complete quantum theory of gravity, we do know some of the features it is expected to exhibit. Most notably, the fabric of space-time itself would be subject to the intrinsic uncertainty present in all quantum theories and fluctuate at tiny distance scales~\cite{PhysRev.97.511, Hawking}. This is far cry from the smooth, flat picture of space-time we are familiar with in the macroscopic world described by GR. 

The most straightforward consequence of this are so-called \textit{lightcone fluctuations}~\cite{PauliLightcone, Ford1999, gr-qc/9909085, Ellis:1999jf}, where the fluctuating space-time curvature causes variations in the time taken by a particle to travel between two points. Though these fluctuations would be very small, their effects could accumulate over large distances into measurable effects. The wavefunctions of neutrinos propagating in this fluctuating space-time would become increasingly out of phase with each other.

It is also predicted that these space-time fluctuations manifest as so-called \textit{virtual black holes} (VBH)~\cite{Hawking1982,PhysRevD.53.3099}, which are microscopic black holes that form in the vacuum and promptly evaporate. Whilst exotic sounding, this is simply the gravitational analogue of the virtual electron-positron pairs in  the phenomenon of \textit{vacuum polarisation} in quantum electrodynamics (QED). A neutrino encountering a VBH would undergo severe modifications to its propagation, with global symmetries potentially violated in the interaction~\cite{Anchordoqui:2005gj, Harlow:2018jwu, PhysRevD.102.115003, Hellmann:2021jyz}. This could result in neutrino flavour violations, conversions to different particle types or even the loss of the neutrino from the observable Universe altogether~\cite{Anchordoqui:2005gj, Anchordoqui:2006xv, Witten:2017hdv}.

\textbf{State-of-the-art:} A broad range of experimental tests of quantum gravity and the structure of space-time have been performed, ranging from high precision photon interferometry laboratory experiments~\cite{Chou:2015sle} to astrophysical observations of cosmic messenger particles such as $\gamma$-rays, neutrinos and gravitational waves~\cite{Lieu:2003ee, Abdo2009, HESS:2011aa, Perlman_2015, Vasileiou2015, PhysRevD.99.083009, Cooke:2020rco, Amelino-Camelia:2016fuh, ELLIS2019352, PhysRevD.102.063027, Wei:2018ajw, Calcagni:2020ume}. There have also been experimental searches for the features predicted by some of the leading theories seeking to describe quantum gravity, such as the additional space-time dimensions predicted by string/brane theories~\cite{Aad:2012ic, Carena:2017qhd, Sirunyan:2018ipj}, or violations of Lorentz invariance, $CPT$ symmetry or the weak equivalence principal~\cite{Bennett:2007aa, Aartsen:2017ibm, ELLIS2019352, PhysRevD.102.063027, Wei:2018ajw, Daniel:2015mua, Pruttivarasin:2014pja, Kostelecky:2015dpa, Abe:2014wla, Kostelecky:2013rv}. No signal of quantum gravity has been detected thus far however despite our knowledge that such a theory must exist, and without an accepted theory to guide us it is essential to perform the broadest range of tests possible and seek to continually increase sensitivity to these suppressed effects. \\

% TODO neutrinos


% It is also often predicted that these fluctuations can collapse to form so-called `virtual black holes' (VBH)~\cite{Hawking1982,PhysRevD.53.3099}, which are minuscule and quickly evaporate. Whilst this sounds exotic, it is in fact simply the gravitational analogue of the virtual electron-positron pairs that are fundamental to our understanding of the electromagnetic force. A neutrino encountering a VBH would likely experience significant disruption and/or loss of quantum information~\cite{hep-th/9508151}, resulting in decoherence. 



% Neutrinos travelling from source to detector thus become increasingly out of phase with each other.

% Though these fluctuations would be very small, their effects accumulate over large distances. It is also often predicted that these fluctuations can collapse to form so-called `virtual black holes' (VBH)~\cite{Hawking1982,PhysRevD.53.3099}, which are minuscule and quickly evaporate. Whilst this sounds exotic, it is in fact simply the gravitational analogue of the virtual electron-positron pairs that are fundamental to our understanding of the electromagnetic force. A neutrino encountering a VBH would likely experience significant disruption and/or loss of quantum information~\cite{hep-th/9508151}, resulting in decoherence. 

% Particle's propagating in this fluctuating space-time 

% In the absence of an accepted theory of quantum gravity, it is necessary to test many scenarios. A key feature expected in quantum gravity is that space-time itself is subject to the inherent uncertainty of quantum mechanics and fluctuates at very small distance scales~\cite{misner1973gravitation}. This is precisely the kind of stochastic environment that would produce neutrino decoherence~\cite{Mavromatos_2009,PhysRevD.102.115003}. %This project will exploit the unparalleled sensitivity of neutrinos to decoherence to search for both specific quantum gravity scenarios and a more general approach that is sensitive to decoherence effects from a broad range of sources. 

% The most straightforward such decoherence mechanisms are so-called `lightcone' fluctuations\cite{Ford1999, gr-qc/9909085}, where the fluctuating space-time curvature causes the travel distance/time between two points to fluctuate. Neutrinos travelling from source to detector thus become increasingly out of phase with each other, leading to decoherence. Though these fluctuations would be very small, their effects accumulate over large distances. It is also often predicted that these fluctuations can collapse to form so-called `virtual black holes' (VBH)~\cite{Hawking1982,PhysRevD.53.3099}, which are minuscule and quickly evaporate. Whilst this sounds exotic, it is in fact simply the gravitational analogue of the virtual electron-positron pairs that are fundamental to our understanding of the electromagnetic force. A neutrino encountering a VBH would likely experience significant disruption and/or loss of quantum information~\cite{hep-th/9508151}, resulting in decoherence. 

% % A stronger, highly promising signal occurs if these fluctuations sufficiently curve space-time sufficiently in a miniscule volume to collapse and form a singularity, creating a microscopic `virtual black hole' (VBH) which quickly evaporates (analogous to the well known virtual electron-positron pairs of the electromagnetic force). A neutrino encountering a VBH would likely experience significant wavefunction disruption and/or the loss of quantum information~\cite{hep-th/9508151}, which I have shown can produce observable effects even if only a small fraction of detected neutrinos experience such an event. 

% % , which I have shown can produce observable effects even if only a small fraction of detected neutrinos experience such an event.

% I have developed a phenomenological model of the influence of neutrino-VBH ($\nu$-VBH) interactions on neutrino propagation in a range of well motivated scenarios~\cite{PhysRevD.102.115003}, and remarkably have demonstrated that \textbf{sensitivity to Planck-scale physics can be achieved using the high-energy neutrinos detected by the IceCube neutrino observatory} (see Fig. \ref{fig:planck_scale_coherence_length}), even if only a small fraction of neutrinos undergo these encounters. I have recently also developed a model of neutrino decoherence from lightcone fluctuations\todo{Add referecnce once submitted} (submitted to PhysRevD), accounting for both fluctuating space-time curvature and also scenarios where the speed of light fluctuates for high energy particles  (so-called \textit{stochastic Lorentz invariance violation}~\cite{Vasileiou2015}). I will perform stringent experimental tests of these models in this project.

\subsection{Neutrino oscillations and decoherence}

\begin{figure}
%\begin{subfigure}[t]{0.5\textwidth}
    \begin{subfigure}[b]{0.5\textwidth}
    \centering
    \includegraphics[trim=0.0cm 12.7cm 0.cm 0.2cm, clip=true, width=1.\linewidth]{images/atmo_oscillogram_randomize_flavor_n0_matter.png}
    \caption{}
    \end{subfigure}
    \begin{subfigure}[b]{0.5\textwidth}
    \centering
    \includegraphics[trim=0.0cm 12.7cm 0.cm 0.2cm, clip=true, width=1.\linewidth]{images/atmo_oscillogram_randomize_flavor_n2_matter.png}
    \caption{}
    \end{subfigure}
    \caption{Modified atmospheric neutrino oscillations vs. neutrino energy (x axis) and arrival direction (y axis) in my $\nu$-VBH interaction decoherence models, showing (a) energy-independent and (b) $E^2$ suppressed scenarios (to which accelerator experiments are blind)~\cite{PhysRevD.102.115003}. Detectable features are present across a broad range of energies.}
    \label{fig:decoh_oscillograms}
\end{figure}

Neutrinos exhibit the peculiar phenomenon of \textit{neutrino oscillations} where a neutrino produced as one type (\textit{flavour}) may be detected later as another~\cite{Fukuda:1998mi, Ahmad:2001an,Ahmad:2002jz}. This is a consequence of mixing between neutrino mass and flavour states, and the detection of these oscillations implies that neutrinos have non-zero (albeit tiny) masses, contrary to the Standard Model (SM) of particle physics, providing one of the only confirmed experimental signs of Beyond Standard Model (BSM) physics today. These oscillations are characterised by \textit{mixing angles}, describing the mixing between mass/flavour states (controlling the oscillation amplitudes) and \textit{mass splittings}, which are the difference between the (squared) neutrino masses (controlling the oscillation frequencies), and the measurement of these oscillations is a major field of active research today.

However, the quantum superposition effect producing these oscillations would be disrupted for neutrinos propagating in fluctuating space-time, resulting in the damping of neutrino oscillations and averaging of neutrino flavours in a process known as neutrino decoherence~\cite{Benatti_2000, PhysRevLett.85.1166}. The oscillating nature of neutrinos and their ability to travel vast distances unperturbed by the other forces of nature makes them uniquely sensitive to decoherence effects from quantum gravity, with the neutrinos acting as tiny quantum interferometers. Decoherence measurements are potentially sensitive to a range of new physics scenarios~\cite{Mavromatos2010, AmelinoCamelia:2008qg, Perlman_2015, Harlow:2018jwu, Hellmann:2021jyz, 1909.11271, EPJC802020, Capozzi:2018bps, 1904.02518}, including those only accessible via the gravitational force (to which nearly all other particle physics measurements are essentially blind)~\cite{Hellmann:2021jyz}.

I have developed phenomenological models of the influence of neutrino-VBH ($\nu$-VBH) interactions on neutrino propagation in a range of scenarios (including flavour violations, democratic population of particle states, severe phase perturbations and total loss of the neutrino)~\cite{PhysRevD.102.115003} (see Fig. \ref{fig:decoh_oscillograms}), and remarkably have demonstrated that the resulting damping effect from \textit{natural} Planck scale physics can be resolved using neutrino oscillation measurements by the IceCube neutrino observatory, even if only a small fraction of neutrinos undergo these encounters. I have also very recently developed a model of neutrino decoherence resulting from lightcone fluctuations~\cite{2103.15313} (submitted to the journal \textit{Phys. Rev. D}), accounting for both fluctuating space-time curvature and also scenarios where the speed of light is uncertain/variable for high energy particles (so-called \textit{stochastic Lorentz invariance violation}~\cite{Vasileiou2015, Amelino-Camelia:2016fuh}), yielding further potential signals in IceCube data. These models are the first to directly connect the potentially observable phenomenology of neutrino decoherence to the underlying microphysics of a quantum theory of gravity, allowing experimental constraints on the fundamental nature of space-time to be made using decoherence measurements for the first time in this project.

\textbf{State-of-the-art:} Decoherence searches have been performed using neutrinos from nuclear reactors, the Sun, the Earth's atmosphere and particle accelerators~\cite{PhysRevLett.85.1166, Abbasi:2009nfa, PhysRevD.89.053002, Bakhti:2015dca, Coelho:2017zes, PhysRevD.95.113005, Coloma:2018idr, de_Holanda_2020}, generally using simplified mathematical expressions rather than specific models, with no signal observed thus far. Despite the large distances travelled, neutrinos of extragalactic origin are not in general well suited to decoherence searches due to the incoherent nature of the sources of these neutrinos and degeneracies between the expected flavour composition in conventional vs. decoherence scenarios~\cite{PhysRevD.102.115003}. Planck scale constraints on lightcone fluctuations exist for high energy $\gamma$-rays via tests of arrival time spread in $\gamma$-ray bursts (GRB) and quasar image degradation~\cite{Perlman_2015} but only under highly optimistic assumptions such as no energy suppression of Planck scale effects or the highly correlated fluctuations between different space-time regions (and even then only with mild energy suppression)~\cite{2103.15313}, and in the absence of an underlying model no correspondence between the effects of fluctuating space-time on photons and neutrinos can be assumed. Decoherence effects resulting from quantum gravity are expected to be energy-suppressed, and the strongest constraints to these signals to date were set using low statistics publicly released IceCube data (by non-collaboration authors)~\cite{Coloma:2018idr}. The measurements I will perform will exceed the sensitivity of these results by orders of magnitude, measure new strongly energy-suppressed (cubic and quartic) scenarios that have not previously been experimentally tested, test an unprecedented range of specific models, and include a robust treatment of systematic uncertainties not present in previous works, representing a major leap forward in this field. \\

% TODO ref subir paper about why photns and neutrinos may experience different fluctuations
% \todo{Proton decay}
% \todo{GRB lightcone}
% \todo{Lightcone holographic}

% \noindent \textbf{State-of-the-art:} High er E and longer baseline at LBL.

%I will perform stringent experimental tests of these models in this project.

%Decoherence is highly suppressed and as yet unoberved for neutrinos

% oscillations are coherent, meaning that the states of neutrinos of the same energy travelling the same path will evolve identically. This would be disrupted however if neutrinos couple to a stochastic environment in a process known as decoherence, observable as the \textbf{damping of neutrino oscillations} over distance (see Fig. \ref{fig:decoherence}). Decoherence is known in other quantum systems, but is highly suppressed and as yet unobserved for neutrinos due to their extremely feeble interactions with other (known) particles isolating them from their environment.

% Neutrinos propagate as a superposition of three quantum states, giving rise to the peculiar phenomenon of \textit{neutrino oscillations} where a neutrino produced as one type (\textit{flavour}) may be detected later as another~\cite{Fukuda:1998mi, Ahmad:2001an,Ahmad:2002jz}. These oscillations are coherent, meaning that the states of neutrinos of the same energy travelling the same path will evolve identically. This would be disrupted however if neutrinos couple to a stochastic environment in a process known as decoherence, observable as the \textbf{damping of neutrino oscillations} over distance (see Fig. \ref{fig:decoherence}). Decoherence is known in other quantum systems, but is highly suppressed and as yet unobserved for neutrinos due to their extremely feeble interactions with other (known) particles isolating them from their environment.

% I have developed a phenomenological model of the influence of neutrino-VBH ($\nu$-VBH) interactions on neutrino propagation in a range of well motivated scenarios~\cite{PhysRevD.102.115003}, and remarkably have demonstrated that \textbf{sensitivity to Planck-scale physics can be achieved using the high-energy neutrinos detected by the IceCube neutrino observatory} (see Fig. \ref{fig:planck_scale_coherence_length}), even if only a small fraction of neutrinos undergo these encounters. I have recently also developed a model of neutrino decoherence from lightcone fluctuations\todo{Add referecnce once submitted} (submitted to PhysRevD), accounting for both fluctuating space-time curvature and also scenarios where the speed of light fluctuates for high energy particles  (so-called \textit{stochastic Lorentz invariance violation}~\cite{Vasileiou2015}). I will perform stringent experimental tests of these models in this project.

% Decoherence can result in a range of scenarios, including quantum gravity, neutrino interactions with Dark Matter~\cite{1909.11271, EPJC802020}, string theory~\cite{Ellis:1997jw,doi:10.1142/S0217732397000248,PhysRevD.80.124019,Mavromatos2010}, diffuse gravitational waves~\cite{Dvornikov_2020}, and can reveal whether neutrinos are their own antiparticle~\cite{CAPOLUPO2019298, 2001.07580}. Decoherence measurements can thus confront some of the biggest questions in particle physics.


\subsection{$CPT$ violation and matter-antimatter asymmetry}

% \textbf{TODO Need a new $CPT$-V figure, choose a less extreme scenario rather than trying to motivate the full E range (decoherence does that already)}

% \begin{wrapfigure}{R}{0.43\textwidth} %this figure will be at the right
\begin{wrapfigure}{R}{0.43\textwidth} %this figure will be at the right
    \centering
    % \vspace{-9pt}
    \includegraphics[trim=0.0cm 0.0cm 0.cm 0.0cm, clip=true, width=1.\linewidth]{images/CPTv_IceCube.pdf}
	\caption{Asymmetry between neutrino and antineutrino oscillation probability in the presence of $CPT$-V, showing potential energy-suppressed signals not excluded by any previous $CPT$-V oscillation searches. No asymmetry is expected if $CPT$ is not violated, meaning any observed difference must result from new physics. Differences in (anti)neutrino masses can produce anomalous oscillation signals across a broad range of energies, whereas signals of (anti)neutrino mixing angle deviations are confined to the GeV region.}
% 	\vspace{-7pt}
	\label{fig:$CPT$v}
\end{wrapfigure}

If gravity is a quantum force then the uncertain nature of space-time can result in differing properties between matter and antimatter, known as $CPT$ violation ($CPT$-V)~\cite{Mavromatos:2005mi, AmelinoCamelia:2008qg, RalfLehnert:2016grl}. For example, $CPT$ symmetry is only valid in (a) flat space-time, and thus may be violated due to the fluctuating microscopic nature of  space-time in a quantum theory of gravity, and (b) a \textit{unitarity} quantum theory (one where quantum information/probability is conserved), whereas in a Universe permeated by VBHs quantum information could be lost beyond these microscopic event horizons, resulting in apparent violations of unitarity and $CPT$ symmetry~\cite{Mavromatos:2005mi}. More generally, $CPT$-V is a frequent prediction of the many variations of potential quantum gravity theories such as string theory~\cite{Mavromatos:2005mi, Hashimoto:2014aoa, Ellis:2013gca}.

For neutrinos, $CPT$-V predicts differing oscillation frequencies and amplitudes between neutrinos and antineutrinos through differing mass splittings and mixing angles~\cite{Barenboim:2017ewj}, a potentially observable signal. These effects are likely suppressed at energies below the Planck scale, but this can be partially overcome in the high energy (orders of magnitude above any long baseline accelerator experiment), high statistics measurements of neutrino oscillations made possible by the vast size of IceCube  to yield sensitivity to signals to which all other experiments would be blind (see Fig. \ref{fig:$CPT$v}). 

Detecting $CPT$-V would have profound consequences even beyond the search for quantum gravity. One of the biggest questions in physics is why the Universe appears to almost entirely consist of matter, and not antimatter, since (in the absence of $CPT$-V or other new physics) both are expected to have been produced equally~\cite{Sakharov_1991}. The very fact we are even here to ponder this question is a consequence of this, since without this imbalance all matter and antimatter would have annihilated to leave a Universe devoid of stars, planets or life. Known differences between matter/antimatter (so-called $CP$-violations) can only account for a tiny fraction of the observed imbalance, meaning that new physics like $CPT$-V must exist. The energy-suppressed $CPT$-V I will search for is an excellent candidate to explain this, as these effects would have been strong in the high temperatures of the early Universe when (anti)matter was forming~\cite{Mavromatos:2017cxr, hep-ph/9809542, Ellis:2013gca}. Furthermore, tensions have emerged in neutrino vs antineutrino oscillation measurements~\cite{Abe:2019vii,NOvA_CP_result}, potentially indicating the presence of new physics that this project could reveal, making this measurement more important than ever.

% \todo{More generally $CPT$-V from scattering on matter/backgrounds~\cite{Capolupo:2020myw}? Maybe motivate with the fact that standad matter effects are $CPT$ violating, and so $CPT$ effects from unknown backgrounds are well motivated.}

\noindent \textbf{State-of-the-art:} In the absence of a concrete model of quantum gravity (or other $CPT$-V theory) it is essential to probe the broadest possible range of signals~\cite{hep-ph/9809542} for signs of $CPT$-V. Experimental constraints exist for neutral kaons~\cite{Ellis:1999xh, Ambrosino:2006ek, Abouzaid:2010ny, Babusci:2013gda, Schubert:2014ska}, neutrinos~\cite{Adamson:2013whj, Ohlsson:2014cha}, hadron colliders~\cite{Aad:2013eva, vanTilburg:2016awx} and in precision tests of low energy systems such as particle magnetic moment measurements~\cite{Bluhm:1997ci, Bennett:2007aa} and (anti)hydrogen spectroscopy~\cite{Kostelecky:2015nma}, with no observed signal to date. This indicates that such effects must be highly suppressed, as expected in a quantum theory of gravity. The sensitivity of neutrino oscillations to very small (sub-eV) mass differences makes them one of the best motivated search channels~\cite{PhysRevD.99.075022}, and the measurements in this work will test $CPT$-V at orders of magnitude higher energies that existing limits with accelerator neutrinos. Additionally, under my leadership the precision of IceCube's neutrino oscillation measurements has reached parity with accelerator experiments for the first time, and will surpass this during this project with the data from the next-generation IceCube Upgrade. Coupled with pioneering (anti)neutrino separation methods I will develop, this project will afford unparalleled sensitivity to energy-suppressed $CPT$-V in neutrino oscillations. \\

%\todo{ALPHA experiment}

% \begin{wrapfigure}{R}{0.45\textwidth} %this figure will be at the right
%     \centering
% 		\includegraphics[width=1.\linewidth]{images/atmo_osc.png}
% 		\caption{Neutrinos produced in the atmosphere cross the Earth before detection in IceCube, oscillating and potentially experiencing the influence of quantum gravity as they propagate.}
% 		\vspace{-7pt}
% 		\label{fig:atmo_osc}
% \end{wrapfigure}

% The concept of \textit{symmetries} in physics are fundamental to understanding of the microscopic world. 
% Charge-Parity-Time ($CPT$) symmetry - meaning that the physics of a system remains unchanged when simultaneously the charge flips, directions are mirrored and the direction of time reverses - is a cornerstone of the quantum field theories that have described our Universe at microscopic scales with unprecedented success. However, the fundamental conditions required for $CPT$ symmetry are not expected to hold in a quantum theory of gravity (for example due to the fluctuating nature of space-time), leading to the prediction that $CPT$ symmetry may be violated at some energy scale~\cite{Mavromatos:2005mi, RalfLehnert:2016grl}. An experimental signature of $CPT$ violation ($CPT$-V) would be a game changing result in the search for quantum gravity and more generally would shake the foundations of quantum field theories.

% A potential consequence of $CPT$-V is differing properties such as mass between particles and antiparticles, which for neutrinos would manifest as differing oscillations for neutrinos and antineutrinos~\cite{Ohlsson:2014cha, Barenboim:2017ewj}. Such effects have been probed with neutral kaons and neutrinos~\cite{TAKEUCHI201279, Adamson:2013whj}, but I have identified that the atmospheric neutrino oscillations observed by IceCube (orders of magnitude higher energy than any other experiment) are likely far more sensitive to such effects, given that $CPT$-V (and other effects of Planck scale physics) are expected to be suppressed at low energies. Fig. \ref{fig:$CPT$v} shows two example $CPT$-V scenarios (in an energy-dependent model I have developed) that produce significant effects for IceCube but would not have been detected by previous searches with accelerators, and I will perform the world's most sensitive search for energy-dependent $CPT$-V. 


% \todo{Another possible manifestation...}Additionally, potential $CPT$-V effects in neutrino decoherence have been identified~\cite{Mavromatos_2009, Barenboim:2004wu, Carrasco:2018sca}, providing a powerful synergy between the elements of this proposal. I have shown that such effects can produce potentially observable signals for high energy neutrinos in IceCube, and will also test these effects in this work. 


\subsection{The IceCube neutrino observatory and the IceCube Upgrade}

% \begin{wrapfigure}{R}{0.5\textwidth} %this figure will be at the right
%     \centering
% 	\includegraphics[width=1.\linewidth]{images/IceCube_1200x.jpg}
% 	\caption{The IceCube neutrino observatory at the South Pole. Cherekov light from neutrino interactions in the glacial ice deep below the surface are detected by PMTs.}
% % 		\vspace{-7pt}
% 	\label{fig:atmo_osc}
% \end{wrapfigure}

\begin{figure}
%\begin{subfigure}[t]{0.5\textwidth}
    \begin{subfigure}[c]{0.65\textwidth}
    \centering
    \includegraphics[width=0.9\linewidth]{images/IceCube_1200x.jpg}
    \caption{\label{fig:icecube}}
    \end{subfigure}
    \begin{subfigure}[c]{0.35\textwidth}
    \centering
    \includegraphics[width=0.9\linewidth]{images/mdom.jpg}
    \caption{\label{fig:mDOM}}
    \end{subfigure}
    \caption{(a) The IceCube neutrino observatory at the South Pole. Cherekov light from neutrino interactions in the glacial ice deep below the surface is detected by PMTs. (b) One of the new multi-PMT optical modules to be installed in the IceCube Upgrade.}
\end{figure}

The IceCube neutrino observatory~\cite{Aartsen_2017}, located at the geographic South Pole, instruments a vast 1 billion tons of glacial ice $\sim$2 km below the surface with 5160 optical sensors, each containing a single photo-multipier tube (PMT), to detect Cherenkov light produced by the interactions of neutrinos in the ice. This truly colossal 1 Gton detector detects huge numbers of neutrinos produced in air showers when cosmic rays slam into the Earth's atmosphere, many of which oscillate from muon to tau flavoured as they cross the Earth, as well as neutrinos of extra-galactic origin. These neutrinos are detected across a staggering six orders of magnitude in energy (GeV to PeV), dwarfing the energy reach of even particle colliders. 

%These high-energy neutrinos with long travel distances are perfect to search for decoherence from Planck-scale physics, and the huge statistics allows even very weak effects to be probed (crucial for quantum gravity). 

% \begin{wrapfigure}{R}{0.4\textwidth} %this figure will be at the right
%     \centering
% 	\includegraphics[width=1.\linewidth]{images/mdom.jpg}
% 	\caption{One of the new multi-PM optical modules to be installed in the IceCube Upgrade.}
% % 		\vspace{-7pt}
% 	\label{fig:mDOM}
% \end{wrapfigure}


Furthermore, in 2023-24 IceCube will be substantially upgraded~\cite{IceCubeUpgrade_ICRC2019} with 700 sensitive new multi-PMT optical modules, dramatically increasing the instrumentation density in a 2 Mton core. I lead the international group conducting the simulation studies of the goals and performance of the IceCube Upgrade experiment~\cite{IceCubeUpgrade_ICRC2019, NuFactProceedings}, which show factor 2-4 improvements in detector efficiency and resolution, providing a truly next-generation precision neutrino physics facility. Additionally, a host of new calibration devices will be deployed to allow precise characterisation of the natural detection medium and significantly reduce systematic uncertainties, crucial when seeking small signals such as suppressed quantum gravity effects.\\

% \todo{Upgrade good fro high stats (small signals) and separating small nu/nubar effects}


% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------

\section{Methodology}
\vspace{0.1 cm}

% \textbf{From instructions:} Describe the proposed methodology in detail including any key
% intermediate goals. Explain and justify the methodology in relation to the state of the art, and
% particularly novel or unconventional aspects addressing the 'high-risk/high-gain' balance. Highlight
% any intermediate stages where results may require adjustments to the project planning. 

% \todo{Need clear deliverables in each of these sections in B2, and plans for problems}

The core deliverables of this project are the world's most sensitive (and in many cases first) searches for neutrino decoherence and $CPT$-V in neutrino oscillations, unique signatures of quantum gravity and the underlying nature of space-time. I will develop state-of-the-art simulations and a high statistics data sample that will form the core of these measurements, and pioneer the first use of neutrino-antineutrino separation techniques in neutrino telescopes. These elements will be integrated into my existing oscillation statistical analysis framework, modified to include the new systematic uncertainty and signal modelling. The measurements will search for distortions in the atmospheric neutrino spectrum in IceCube in 4-dimensions; reconstructed neutrino energy, arrival direction (a proxy for travel distance), particle type (using the topology of the event to distinguish between muon neutrino interactions with track-like topologies vs. all other cases, which are more spherical in nature), and neutrino vs antineutrino, comparing the observed detector data with the simulated detector response to the new physics signals tested. 

Since the specific quantum nature of gravity is not known but its effects are expected to be suppressed at observable energy scales, the analysis strategy is to maximise sensitivity by testing the broadest possible range of signals across the maximum possible neutrino energy range, maximising statistics and developing novel methods to suppress sources of systematic uncertainty, allowing the weakest possible signals to be probed.  \\


\subsection{Project management}

This project will be carried out by myself as PI, one postdoc and two Ph.D. students, with the timeline and division of tasks/milestones shown in Fig. \ref{fig:timeline}. For an early career researcher I have considerable research and team management experience which I will draw upon in this project, having lead an international team of 13 postdocs and Ph.D. students in the latest generation of IceCube neutrino oscillation measurements, co-supervised five MSc students and one BSc student at my home institute , the Niels Bohr Institute (NBI), and lead a small team of six engineers across three countries in the space industry prior to my academic career. I will spend $\sim$90\% of my time on these project activities and will play an active role in the research (I will not have teaching responsibilities during this time period) and will in general be sharing tasks with my group members to maximise supervision efficiency.

\begin{figure}[h]
%\begin{subfigure}[t]{0.5\textwidth}
    \begin{subfigure}[c]{1.\textwidth}
    \centering
    \includegraphics[trim=1.7cm 11.1cm 1.7cm 1.0cm, clip=true, width=0.99\linewidth]{images/TaskPlanning.pdf}
    \end{subfigure}
    \begin{subfigure}[c]{1.\textwidth}
    \centering
    \includegraphics[trim=1.7cm 11.5cm 12.3cm 1.5cm, clip=true, width=0.5\linewidth]{images/TaskPlanningLegend.pdf}
    \end{subfigure}
	\caption{Project timeline for all team members and the IceCube (Upgrade) detector. The key to the task labels and the time allocation for each is shown in the lower panel.}
	\label{fig:timeline}
\end{figure}

Detector simulation is prioritised early in the project to coincide with laboratory testing of the new optical modules, and my team (along with many other IceCube early career researchers) will travel to the South Pole to support the IceCube Upgrade installation and commissioning process. Data analysis constitutes the later stages of the project once all necessary preceding tasks are complete (since these are all inputs to the measurements) and $\gtrsim$2 years of IceCube Upgrade data has accumulated. Buffer time is available at the end of the project in case of delays in hiring, or overrunning Ph.D. projects.

Access to IceCube data and the necessary high performance computing resources is via my IceCube collaboration membership, for which there is a budgeted maintenance/operations fee. Additional computing resources are available at NBI (owned by NBI IceCube PI, Associate Professor D. Jason Koskinen). \\

\subsection{Neutrino-antineutrino separation}

The interactions of neutrinos and antineutrinos cannot currently be distinguished in IceCube oscillation measurements, gravely limiting the sensitivity to new physics producing differing effects between the two such as $CPT$-V. However, there are properties of the interactions that can in principal separate neutrinos and antineutrinos for muon neutrino charged-current interactions (constituting $\sim$65\% of events in existing IceCube oscillation data samples), as well tau neutrino charged-current interactions with final state muons (17\%);

\begin{itemize}[leftmargin=*]
    \item The \textit{inelasticity} of the event, meaning the fraction of the incoming neutrino energy transferred to the ice nucleus in the interaction, which is on average $\sim$10-50\%  higher for neutrinos than antineutrinos in the energy range of interest (see Fig. \ref{fig:inelasticity}).
    \item The (anti)muons produced in muon (anti)neutrino interactions eventually come to rest and decay in the ice, producing a \textit{Michel electron} that yields delayed light a few microseconds later in the detector ($\sim$5000 photons per decay). The lifetime of this decay differs by $\sim$400 nanosecond for muons and antimuons due to capture of muons on oxygen nuclei in the ice, meaning that the time of this delayed light can distinguish between neutrino and antineutrino events (see Fig. \ref{fig:michel_electron}). 
\end{itemize}

The neutrino inelasticity for a muon neutrino charged-current interaction can be reconstructed by separately reconstructing the approximately spherical light emission from the break up of the ice nucleus and the track-like light emission from the muon also produced in the interaction. This has been demonstrated for TeV events in IceCube~\cite{Aartsen:2018vez} but its power for (anti)neutrino separation is thus far little explored. More recently I have demonstrated that inelasticity can be reconstructed for lower energy (GeV) events (where neutrino oscillation signals are strong) with $\sim$30\% precision, and with the more densely instrumented IceCube Upgrade precision of $\sim$10\% is expected. 

\begin{wrapfigure}{R}{0.5\textwidth} %this figure will be at the right
    \centering
    % \vspace{-7pt}
    \includegraphics[trim=2.0cm 0.0cm 1.0cm 0.0cm, clip=true, width=\linewidth]{images/inelasticity.png}
    % \end{subfigure}
    \caption{The average inelasticity, $\langle y \rangle$, of neutrino (blue) and antineutrino (green) interactions in IceCube, which differs in the energy range probed in this work~\cite{Aartsen:2018vez}. Reconstructing the inelasticity in IceCube events can thus be used to distinguish (anti)neutrino interactions.}
    % \vspace{-7pt}
    \label{fig:inelasticity}
\end{wrapfigure}

Additionally, within the oscillation physics working group I lead we have recently taken the first steps in the detection of delayed light from Michel electrons, successfully identifying delayed light for $\sim$5\% of events using simple methods and demonstrating the feasibility of this technique. This performance will significantly improve with more sophisticated methods and in particular with the deployment of the IceCube Upgrade, with the far higher sensor density better able to identify the dim delayed light signals, and the improved muon track reconstruction allowing the precise location of the muon decay position and thus the expected location of the delayed light signal (suppressing `false positive' signals from detector noise). 

% \todo{More details on how to tag the light}

I will build on these initial studies to pioneer the first use (anti)neutrino separation in IceCube neutrino oscillation measurements. This will require development of inelasticity reconstruction across the full energy range of IceCube, verification of the theoretical modelling of inelasticity in neutrino event generators and modelling of the associated systematic uncertainty, and development of delayed light tagging methods for the IceCube Upgrade. I will exploit the vast flux of muons from cosmic ray air showers observed by IceCube to develop and verify the delayed light tagging method with high statistics and independently of the neutrino signals, exploiting a synergy with the NBI group of Associate Professor D. Jason Koskinen who are developing a sample of stopped muons in the detector for calibration studies that can also be used and developed in this study. 

\begin{wrapfigure}{R}{0.5\textwidth} %this figure will be at the right
    \centering
    % \vspace{-7pt}
    \includegraphics[trim=0.0cm 0.0cm 0.0cm 0.0cm, clip=true, width=\linewidth]{images/michel_electron.png}
    % \end{subfigure}
    \caption{A muon ($\mu$) from a neutrino interaction deposits light in the detector (leading to a reconstructable track) before stopping. Microseconds later the stopped muon decays, producing a Michel electron ($e$) which itself produces detectable light in the nearest sensor. }
    % \vspace{-7pt}
    \label{fig:michel_electron}
\end{wrapfigure}

Neither of these methods can unequivocally identify an event as a neutrino or antineutrino, but instead can be used to form neutrino and antineutrino enriched sub-samples, achieving statistical separation in a similar manner to existing flavour identification techniques in IceCube. The two methods are complimentary (e.g. both inelasticity can be reconstructed and delayed light tagged for a single event) and will be combined in a machine learning classifier model alongside correlated data features (in particular the track reconstruction uncertainty) to produce a single prediction for each event. As a baseline I will use \textit{extreme gradient boosted decision tree ensembles}~\cite{Chen:2016btl} for this task which I have found to have very strong classification performance in cases such as this with clearly defined input data features, having used these methods previously (in combination with data pre-processing techniques like \textit{sample-balancing}) to produce the current state-of-the-art background rejection and flavour identification methods in IceCube. I will however also investigate the use of deep learning methods to determine if stronger classification performance can be achieved (directly translating to $CPT$-V measurement sensitivity), building on my ongoing collaboration with NBI colleagues from the ATLAS experiment at the LHC (Associate Professor Troels Petersen's group) with whom I have made major strides in machine learning reconstruction techniques in IceCube (discussed further in Section \ref{sec:event_sample}).
 
\textbf{Risk/Gain:} This is the single most challenging element of this project, requiring the development and integration of multiple brand new experimental methods. However, a successful (anti)neutrino classifier will be game-changing for IceCube oscillation physics, paving the way for new physics searches with differing (anti)neutrino signals including Non-Standard Interactions (NSI) (likely yielding the first constraints on the imaginary components of such effects for some couplings), sterile neutrinos and the determination of the neutrino mass ordering (via a matter resonance for core crossing neutrinos or antineutrinos), not to mention the $CPT$-V searches in this project. These methods can also be used to probe the antineutrino content of the astrophysical neutrino flux observed by IceCube~\cite{Aartsen:2013jdh}, constraining their production mechanisms (a major open question in neutrino astronomy)~\cite{glashow_icecube}. I have allocated significant time resources to this project, and it is prioritised early in the timeline so that additional resources can be re-allocated to it if major delays are incurred. I will publish a dedicated paper on these pioneering methods in a suitable technical journal, such as the \textit{Journal of Instrumentation}. \\

% \todo{Which NSI couplings?}
% \todo{Which production mechanisms?}

% A natural future extension of these methods would be to also search for delayed light from neutron capture~\cite{Li:2016kra}, potentially giving the ability to distinguish electromagnetic/hadronic showers in the detector, allowing discrimination of electron and tau neutrino interactions, or neutral currents.

\subsection{Detector simulation}

The uncertainty in the scattering and absorption properties of the ice are dominating factors limiting measurement precision in IceCube, but the dense instrumentation in the IceCube Upgrade (with a sensor-sensor distance of 3 m, smaller than the photon scattering length) will significantly reduce the dependence of GeV-scale events on these ice properties, and the accurate modelling of the sensors now becomes critical. Using data from an extensive laboratory test campaign of the new optical modules (conducted by my collaborators at Michigan State University, M{\"u}nster University and DESY-Zeuthen) for reference, I will created data-driven models of the IceCube Upgrade optical modules, including:

\begin{itemize}[leftmargin=*]
    \item The sensor geometry and material properties (including reflection and scattering in the glass) to accurately model the sensitivity of the modules as a function of the position and angle of incidence of the photon arrival at the module surface, using the `industry standard' \texttt{GEANT4}~\cite{Agostinelli:2002hh} software package (replacing the simple and imprecise parametrisations currently used by IceCube), and verified against data from laser scans of the PMT surfaces.
    \item The quantum efficiency of the PMTs as a function of photon wavelength, and the charge distribution resulting from the stochastic amplification (via avalanche secondary electron production in the PMT) of the photoelectron liberated by the photon, accounting for a poorly understood under-amplified low charge component that likely depends on the photon incidence position on the PMT surface. Accurate modelling of the efficiency and charge response of the PMTs is crucial to avoid bias in neutrino energy reconstruction (critical to the energy-dependent signals in this proposal). The time development of the avalanche and resulting \textit{transit time jitter} will also be modelled.
    \item The charge and time distribution of after-pulsing observed in the PMTs over nanosecond and microsecond time scales following the desired photoelectron signal. The underlying cause of these pulses is not fully understood, although they likely at least in part originate from ionisation of residual gas in the PMT~\cite{Ma:2009aw}, but the effects can be modelled using test data. These pulses are a background to the delayed light signal from Michel electrons to be used in the (anti)neutrino separation techniques, and thus accurate modelling is vital to avoid bias in $CPT$-V measurements I will perform. 
    \item The time distribution of detector noise resulting from radioactive decays of impurities in the glass pressure vessel surrounding the PMTs (an order of magnitude higher in rate than existing IceCube sensors), including a correlated Cherenkov component across multiple PMTs in the segmented sensors that mimics neutrino signals. Measurements of radioactivity and scintillation properties of glass samples will be used to simulate these decays in the sensor model and generate correlated hit time distributions that can be sampled to inject noise into the simulated detector response to neutrino interactions used in the decoherence/$CPT$-V measurements. Mis-modelling of this noise would result in biases in the reconstruction of multiple reconstructed neutrino properties used in these measurements, and mis-characterisation of any irreducible coincident noise backgrounds.
    \item The conversion of charge to digital hit signals in the readout electronics, accounting for analog signal shaping, slow (100 MSPS) waveform sampling in the analog to digital converter (ADC), discriminator (determining whether readout is triggered), leading/trailing edge timestamp using a faster (1 GSPS) ADC, on-board waveform extraction, and data packet formation and transmission (including time synchronisation between different sensors). The reconstruction of photon arrival times depends on this chain, and in particular any offset/bias in this process must be carefully modelled as it will directly impact neutrino direction reconstruction, a key input to the analyses in this project.
\end{itemize}

\begin{wrapfigure}{R}{0.45\textwidth} %this figure will be at the right
    \centering
    % \vspace{-7pt}
    \includegraphics[trim=0.0cm 0.0cm 0.cm 1.0cm, clip=true, width=\linewidth]{images/mDOM_noise.png}
    % \end{subfigure}
    \caption{Visualisation of a prototype GEANT4 simulation of one of the new optical sensors in the IceCube Upgrade. A radioactive decay event is shown.}
    % \vspace{-7pt}
    \label{fig:mDOM_sim}
\end{wrapfigure}

These models will also be verified using \textit{in-situ} data from the sensors once deployed in the ice, and my team will travel to the South Pole to assist the detector installation, using these simulations to verify the operation of the deployed hardware in real-time. It is vital that this model development take place in parallel with the laboratory testing campaign (e.g. before the sensors are transported to the South Pole) to allow iteration on the testing procedures should the tests/modelling reveal any expected effects requiring dedicated study, and thus this work is prioritised at the start of the project and assigned to myself and a postdoc, rather than an inexperienced PhD student.
 
Under my leadership as \textit{IceCube Upgrade simulation manager}, my collaborators and I have taken the first steps in developing simple prototypes of these simulations (see Fig. \ref{fig:mDOM_sim}), which were fundamental to demonstrating the physics potential of the IceCube Upgrade and the successful funding of the project. This, combined with my experience in high fidelity detector modelling from my Ph.D. -- where I developed simulations of the tracking detector at the Fermilab muon g-2 experiment, which were a fundamental component of the most precise high energy particle physics measurement in history~\cite{gm2_run1_result} -- and four years of experience as a professional simulations engineer in the space industry before my academic career (developing simulations of the European Space Agency's ExoMars Rover, Solar Orbiter and GAIA missions), makes me ideally suited to this task. These models will form the basis of all future analyses by the 300-person international IceCube collaboration, and thus have an enormous physics impact,  and I will publish a methods paper describing these models and the methods employed in a suitable technical journal (e.g. the \textit{Journal of Instrumentation}). \\

\subsection{Event sample}
\label{sec:event_sample}

\begin{wrapfigure}{R}{0.5\textwidth} %this figure will be at the right
    \centering
    % \vspace{-7pt}
    \includegraphics[trim=0.0cm 0.0cm 0.cm 0.0cm, clip=true, width=\linewidth]{images/OscNext_high_stats_event_selection_levels.png}
    \caption{Atmospheric muons and coincident noise background reduction over many orders of magnitude in my existing IceCube GeV data sample, resulting in neutrino dominated sample with 3\% background contamination. The event sample developed in this project will have $\sim$5$\times$ higher neutrino rates.}
    % \vspace{-7pt}
    \label{fig:event_selection}
\end{wrapfigure}

Oscillation analyses in IceCube have always been split between focusing on the low energy $\mathcal{O}$(25 GeV) regime (though still higher in energy than accelerator measurements) and the high energy TeV+ regime. However, the quantum gravity signals searched for in this project can manifest across the entire GeV to PeV energy range observed by IceCube (see Fig. \ref{fig:decoh_oscillograms}), and I will therefore for the first time create a holistic merger of these regimes, unifying disparate methods developed for enormously varied event topologies (ranging from GeV events depositing light in only a handful of sensors to multi-kilometer muon tracks penetrating the entire Gton detector). In particular I will incorporate TeV+ scale \textit{cascade-like} events in a neutrino oscillation measurement for the first time, since an excess in this channel would indicate the appearance of tau neutrinos from the dominant muon neutrino flux (with predominately \textit{track-like} signatures), a key signal of the anomalous oscillations sought in this work.

The resulting sample will contain well over 1 million neutrinos, unprecedented statistics for high energy neutrino oscillation measurements, affording sensitivity to even the very weak effects of quantum gravity. I will also invert \textit{atmospheric self-veto} techniques~\cite{PhysRevD.90.023009, Arguelles_2018} used to identify and reject atmospheric neutrinos from astrophysical searches (via the identification of coincident atmospheric muons from the same air shower) to instead enhance the high energy atmospheric neutrino content of the sample compared to current methods, maximising the sensitivity to energy suppressed new physics (a PeV neutrino is 100 times more sensitive than a 100 TeV neutrino to $E^2$ suppressed decoherence effects, a well motivated scenario predicted by string theory~\cite{Ellis:1997jw, doi:10.1142/S0217732397000248}) whilst keeping the poorly understood astrophysical neutrino background suppressed.

% \todo{How weak? 1\%?}

Rejecting the $\mathcal{O}(10^6)$ atmospheric muon and coincident detector noise background events that trigger the detector for every neutrino observed is a major challenge. The noise rates are an order of magnitude higher for the new IceCube Upgrade modules, but I will exploit the segmented nature and dense spacing of the new sensors to remove events with light signatures that are not causally consistent with a common vertex (as would be expected for neutrino interactions), building on my experience gained developing the current leading methods for noise rejection in IceCube (the first application of machine learning for this task). More generally I will also update the various background rejection and neutrino reconstruction methods used to integrate the data from the new sensors, in particular exploiting the upwards facing PMTs (all current IceCube PMTs point down) to improve the atmospheric muon veto capabilities, which exclusively originate above the detector.

% TODO ESTES due to better reco, removes corridor issues somehwat

% At the core of these measurements will be the first atmospheric neutrino data sample spanning the full energy reach of IceCube (GeV to PeV), containing well over 1 million neutrinos to provide unprecedented statistics for neutrino physics. This is necessitated by the broad energy range of potential signals probed in this project, and to maximise the sensitivity to the suppressed signals of quantum gravity at even the highest energies I will probe. Both data from the IceCube Upgrade and existing IceCube data (totalling more than 10 years of livetime) will be used to maximise the statistics. The core challenges of the event sample are the rejection of the overwhelming atmospheric muon and coincident noise backgrounds that dominate the detector data (thousands or even millions of which are observed for every neutrino) to yield a pure sample of neutrino events, and to reconstruct the properties of these neutrino interactions (for example the energy, direction and flavour of the incoming neutrino and the resulting interaction products).

% To create this holistic neutrino sample I will unify the disparate existing methods developed by myself (GeV energies) and my collaborators (TeV energies) -- each developed for particular neutrino energy range and event topology (for example fully vs. partially contained events, track-like events from muon neutrino interactions vs. spherical light emission from electron/tau neutrinos, etc) -- and develop them further to integrate the data from the new IceCube Upgrade instrumentation into these methods. The high noise rates in these new optical modules result in coincident noise background rates orders of magnitude higher than for the existing IceCube detector, and isolating and removing these events will be critical to this project. I developed the current leading methods for noise rejection in IceCube (being the first to exploit machine learning for this task), which remove events with light emission that is not causally consistent with a common origin (as would be expected for neutrino interactions), and will significantly expand these methods to exploit the segmented nature and dense spacing of the new sensors.

\textbf{Risk/Gain:} The current state-of-the-art neutrino reconstruction methods used in IceCube cannot be naturally extended to the IceCube Upgrade, as they exploit symmetries in the existing sensor design that do not apply to the new segmented optical modules. \textit{Deep learning neural networks} represent the cutting edge of neutrino reconstruction in accelerator neutrino experiments~\cite{Baldi:2018qhe, Adams:2018bvi}, but the irregular geometry of IceCube cannot easily be transformed into a the pixel structure required by techniques developed by the image processing community which dominate the field (such as \textit{convolutional neural networks}). The development of methods without such limitations is well underway within the IceCube collaboration however, with highly promising results recently achieved using graph and recurrent neutral networks (GNNs and RNNs), with a collaboration between myself and machine learning experts from the ATLAS experiment recently demonstrating a working GNN-based energy and direction reconstruction method which achieves $\sim$30\% improvement over IceCube's current methods, and we will extend these methods to support the IceCube Upgrade. However, should these methods not achieve maturity in time for these measurements, the contingency plan would be to implement approximations in the existing methods to neglect either the directionality afforded by the new sensors or the anisotropy in the ice properties to allow their use with the new detector, at the cost of significantly reducing the reconstruction performance at GeV energies (by a factor $\sim$2), impacting the $CPT$-V measurement sensitivity in particular. \\


\subsection{Monte Carlo Simulation production}

I will produce Monte Carlo (MC) simulations of neutrino interactions and atmospheric muon and coincident noise backgrounds in the detector, utilising the IceCube Upgrade sensor models developed in this work. Once combined with the new physics signal modelling this will be compared to observed data in the decoherence and $CPT$-V measurements. Whilst elements of IceCube's existing simulation chain can be re-used (such as photon propagation software and the atmospheric muon event generator), modelling the GeV to TeV neutrino energy range probed in this analysis requires the integration of a recent extension to the \texttt{GENIE}~\cite{Andreopoulos:2009zz} event generator package (the `industry standard' at GeV energies) that extends the energy range to $>$PeV (from a $\sim$TeV limit previously) and includes modern \textit{next to leading order} (NLO) \textit{parton density functions} (PDFs)~\cite{Garcia:2019hze}. 

\textbf{Risk/Gain:} The cross section modelling used for $<$100 GeV neutrinos in \texttt{GENIE} uses older PDFs (GRV98) than the recent high energy extension, with the main difference being the relative contributions of sea vs. valence light quarks. I am collaborating with Rhorry Gould, a developer of the recent \texttt{GENIE} extension, to implement an update to this $<$100 GeV regime (particularly the low momentum transfer regime) including modeling of systematic uncertainties across the full GeV and TeV energy span, and will integrate these developments into the IceCube simulation chain. If there are major delays in this however, I will instead implement a transition region interpolating the cross section, inelasticity and the 4-mometa of the outgoing particles between the two regimes. I will also integrate \texttt{GENIE} tuning data provided by neutrino accelerator cross section measurements~\cite{Stowell:2019zsh, Acero:2020eit}, which may at least partially correct for the limitations of the current $<$100 GeV \texttt{GENIE} cross section calculations.

% (as they are available with low $Q^2$ Bodek-Yang~\cite{Bodek:2010km} corrections required at this energy range\todo{Am I sure about this?})

% GENIE [11] is currently used as the primary neutrino interaction generator in IceCubes low
% energy analyses. GENIE uses the PDF GRV98 [12] to compute DIS cross sections, which is old and
% misses data from modern experiments. The reason behind this choice is that GRV98 is the most
% recent PDF that has been extrapolated to the low-Q2
% region. This is done by using the corrections
% derived by Bodek-Yang [10] which were tuned specifically for GRV98.

%Previous IceCube used \texttt{GENIE} for GeV oscillation analyses but a distinct in-house event generator for TeV analyses which shows tension in the cross over region of $\mathcal{O}$(500 GeV).


% TODO: This requires the extension of the neutrino-generator GENIE to higher energies than 150 GeV using the cross section models that incorporate the appropriate sea-quark Parton distribution functions~\cite{CSMS}. Alternatively, the use of GENIE at energies < 100 GeV and the use of the IceCube implemented CSMS model at energies >150 GeV can be accomplished by creating a cross-over region from 100-150 GeV where the only the cross sections are transitioned, but also the kinematic form factors of the underlying interactions, e.g. 4-momenta of the outgoing particles from the neutrino interaction, as well as the inelasticity. TODO integrate GENIE HEDIS, manage transition to low E

% Armed with the new detector simulation models, I will produce high statistics Monte Carlo (MC) simulation samples of both neutrino interactions and background events (atmospheric muons and coincident detector noise) in the detector for comparison to observed data in these measurements. This unglamorous but essential work will require the use of recent developments in the state-of-the-art neutrino event generator software \texttt{GENIE}~\cite{Andreopoulos:2009zz, Garcia:2019hze} to for the first time accurately and consistently model neutrino interactions across the many orders of magnitude in neutrino energy probed in this project, particularly in the 100-1000 GeV region which marks the transition between two distinct neutrino cross section calculations. Additionally, I will integrate cross section tuning data provided by accelerator neutrino experiments based on their dedicated neutrino cross section measurements. 


% \todo{Collaboration with Oxford guy}

\textbf{Risk/Gain:} Simulating the extremely high rates of background events observed in the IceCube Upgrade is computationally challenging, potentially creating a bottleneck in these measurements. The simplest mitigation strategy in such a situation is implementing hard cuts in the data sample to sharply suppress backgrounds, at the cost of loss of neutrino events and thus measurement sensitivity. I will also investigate (potentially as MSc projects) new methods for faster background simulation, including parameterising computationally expensive aspects of the simulation, or exploiting cutting edge \textit{generative} machine learning methods to `learn' the event distributions. Both of these methods could significantly reduce the computational load of background MC production, and have been successfully employed at the LHC in recent years~\cite{Barberio:2009zza, ATLAS:2010bfa, Paganini:2017hrr}. I will also use my extensive experience with large scale distributed grid computing, including use of the \textit{Open Science Grid}~\cite{osg07, osg09}, to maximise the resources available for this task. \\

\subsection{Atmospheric muon sideband}

Although the new calibration devices in the IceCube Upgrade will greatly reduce the impact of systematic uncertainties related to the properties of the detector and in particular the optical properties of the ice, the composition of the atmospheric neutrino flux remains a major source of systematic uncertainty due to uncertainties in the spectrum of cosmic rays reaching the Earth, atmospheric conditions, and the modelling of hadronic processes governing the air shower development. These flux uncertainties have degeneracies with energy-dependent decoherence signals and thus can absorb potential new physics signals.

To constrain these flux uncertainties and thus significantly increase the measurement sensitivity to weak quantum gravity signals, I will exploit the copious flux of muons ($\mathcal{O}(10^5)$ detected per neutrino) also produced in these air showers. I will develop a high statistics data sample of well reconstructed muons in IceCube and simultaneously fit this data sideband alongside the neutrino data during these measurements, both strongly constraining the air shower uncertainties and acting as a control sample for evaluating the modelling of the detector independently of the neutrino physics signals, and thus increasing both the sensitivity and robustness of these measurements. This will be the first use of this novel method in IceCube, and will be invaluable in giving confidence in any detected new physics signal. 

%There is synergy here with ongoing activities at NBI, where a muon sample is being developed for calibration of the quantum efficiency of the PMTs which can serve as a starting point for this sideband to accelerate its development.  \\

% \todo{Folded histogram to cancel flux uncertainties}


\subsection{Systematic uncertainty modelling}

The high precision of the measurements proposed here (afforded by the high statistics data sample) and the potentially small signals being sought necessitate a robust treatment of systematic uncertainties. The calibration of the 
the optical sensor models to be developed in this project has associated uncertainties, both due to the precision of the calibration methods and also in cases where time consuming laboratory calibration test are performed only on a sub-sample of modules and their properties extrapolated (e.g. the time/charge distribution of the after-pulsing, and the wavelength dependence of the quantum efficiency). I will produce multiple neutrino, muon and noise MC simulation sets with the sensor model properties varied within the range allowed by the calibration uncertainties to investigate the dependence of the observables in my analyses (e.g, the reconstructed neutrino properties) on these calibration uncertainties, and in cases with significant effects observed (e.g. where neglecting these effects yields biases in the physics measurements of $\gtrsim 0.1 \sigma$, determined using pseudodata experiments) I will produce a parameterisation of the effects controlled by associated \textit{nuisance parameters} representing the calibration uncertainties that I will fit in my measurements alongside the signal parameters.

There will additionally be uncertainty relating the the positions of the sensors in the glacier, which are deployed down 2 km long cables into melted and subsequently re-frozen holes in the ice, which will be calibrated by my IceCube collaborators via the analysis of data from dedicated detector runs where LEDs mounted on the optical sensors are flashed and their light detected by surrounding modules, allowing mapping of the sensor/cable positions/orientations (the cables partially shadow the sensors). I will produce neutrino and background MC simulation sets with varying optical modules positions (within the uncertainties derived from these studies) to again test the impact of the detector uncertainties on my physics measurements, and similarly for uncertainties derived by the IceCube ice calibration working group pertaining to the optical properties of the ice (which will be significantly better calibrated that it is currently thanks to new calibration devices deployed as part of the IceCube Upgrade. I will also integrate advances in atmospheric neutrino flux modelling currently under development by a student at NBI, taking into account the lateral development of the air showers and influence of the Earth's magnetic field.

\textbf{Risk/Gain:} The unprecedented statistical power of this analysis in IceCube may reveal new sources of systematic uncertainty not currently anticipated, which would need to be studied and modelled by my team and our IceCube collaborators. \\

\subsection{Signal modelling}

The decoherence and $CPT$-V measurements will test the influence of quantum gravity on neutrino propagation in a number of models, many for the first time, and the impact of these models must be precisely calculated when computing the simulated signals in the detector. I will implement the impact of these models on neutrino oscillations using the state-of-the-art \texttt{nuSQuIDS} quantum state evolution software~\cite{Delgado:2014kpa, nusquidsGIT}, and integrate them in my existing neutrino data analysis framework. In particular, this will allow accurate modelling of the interplay between new physics effects and the influence of standard matter in the Earth on neutrino propagation (including absorption of high energy neutrinos by the Earth), which has been neglected in many earlier decoherence studies (in some cases leading to spurious signal artefacts)~\cite{PhysRevD.97.115017}. I have experience in this area having already implemented my $\nu$-VBH interaction model using \texttt{nuSQuIDS}, and was the first to properly integrate Earth matter effects in the modelling of decoherence in atmospheric neutrinos.

I will host a specialised workshop on neutrino decoherence and $CPT$-V to further develop the range of potential underlying physics scenarios producing such effects, drawing upon the \textit{COST Action CA18108 (quantum gravity phenomenology)} network of which I am an active member, with a view to testing further models in this project, and I will create MSc projects developing this phenomenology, potentially yielding dedicated publications. I will release all models developed in this work as open source software, allowing other experimental collaborations to test these signals.  \\

%\todo better refs flr BH info theory
% \todo{Connect to proton decay}
% \todo{nu-nubar osc, from CPT-V SME and from nu-VBH}

\subsection{$CPT$-V analysis}

% The event sample and simulations developed in this project will form the core of both the $CPT$-V and decoherence analyses, both of which will also utilise my existing oscillation analysis framework, modified to include the new systematic uncertainty and signal modelling. The measurements will search for distortions in the atmospheric neutrino spectrum in IceCube in 4-dimensions; reconstructed neutrino energy, arrival direction (a proxy for travel distance), particle type (using the topology of the event to distinguish between muon neutrino interactions with track-like topologies vs. all other cases, which are roughly spherical in nature), and neutrino vs antineutrino (using the new methods developed in this project).

For the $CPT$-V search I will test the data for the presence of differing oscillation properties between (anti)neutrinos using a phenomenological parameterisation of these effects of my own devising, yielding the world's first energy-dependent search. The parameterisation is of the form $\Delta \theta = \epsilon (E/\Lambda)^n$, where $\Delta \theta$ is the difference in value of a given neutrino oscillation parameter for neutrinos and antineutrinos (namely the atmospheric mixing angle, $\theta_{23}$ and mass splitting, $\Delta m^2_{32}$), $E$ is the neutrino energy and $\Lambda$ is the energy scale of the new physics producing the $CPT$-V effects, and $\epsilon$ and $n$ characterise the scale and energy-dependence of the effects respectively. This form is equivalent to the energy-independent tests performed in previous measurements~\cite{Adamson:2013whj} when $n=0$, allowing easy comparison of my results with previous literature. The parameters $\epsilon$, $\Lambda$ and $n$ will be fit parameters in the analysis, and additionally specific cases can be tested if compelling model predictions are found (for example a prediction of $\Lambda$ for a new physics theory).

\textbf{Risk/Gain:} This measurement is only possible thanks to the pioneering (anti)neutrino separation methods developed in this project and is thus its success is contingent on the performance of these new methods. The use of two distinct (anti)neutrino separation techniques (inelasticity reconstruction, delayed light tagging) means that should expected issues be encountered with one method the $CPT$-V measurement can still proceed, albeit with reduced sensitivity.

I will also investigate using an alternative model-independent parameterisation of $CPT$-V provided by the \textit{Standard Model Extension} (SME)~\cite{Kostelecky:2011gq} (an effective field theory approach extending the SM to include Lorentz invariance violation) with a view to also making constraints on $CPT$-odd operators in this framework. This framework allows for the possibility of neutrino-antineutrino mixing (resulting in oscillations from neutrinos to antineutrinos and vice versa)~\cite{Mufson:2013yia}, which I will also be able to test for the first time with high energy neutrino telescope oscillation measurements thanks to the (anti)neutrino separation methods developed here.
 
A signal detection in this measurement would be a momentous result, giving one of very few experimental signs of the new physics we know must exist beyond the SM and likely motivating a slew of new models from the theoretical community seeking to explain the observation. In such a case I will target the high profile journal \textit{Nature} to publish these results, whilst if no signal is observed I will place the world's first constraints on energy-dependent $CPT$-V effects in neutrinos and target the journal \textit{Physical Review Letters}.\\

\subsection{Decoherence analysis}

% \todo{nu-VBH nu to nubar transitions}

% \begin{wrapfigure}{R}{0.5\textwidth} %this figure will be at the right
%     \centering
%     \vspace{-7pt}
%     \includegraphics[trim=0.0cm 12.7cm 0.cm 0.2cm, clip=true, width=\linewidth]{images/atmo_oscillogram_randomize_flavour_n0_matter.png}
%     % \end{subfigure}
%     \caption{Modified atmospheric neutrino oscillations (vs neutrino energy and direction) in one of my $\nu$-VBH interaction decoherence models. Detectable features are present across a broad range of energies.}
%     \vspace{-7pt}
%     \label{fig:decoh_oscillograms}
% \end{wrapfigure}
% \todo{E2 fig}

The signal of neutrino decoherence in IceCube is the damping of neutrino oscillations over distance, in particular resulting in the appearance of tau-flavour neutrinos outside of the conventional oscillation signal region, with the signal strongest for neutrinos crossing the full diameter of the Earth before detection. 

In this search I will test a range of decoherence models (a number of which I developed), including $\nu$-VBH interactions and lightcone fluctuations, fitting the underlying model parameters. This work will yield the first ever measurements of the $\nu$-VBH interaction mean free path (in turn constraining how numerous VBHs are and how strongly they interact with neutrinos), the size of the space-time fluctuations experienced by neutrinos, and the intrinsic variability of neutrino velocity. I will also test the possibility that neutrinos can decay, since it shares common damping features to the decoherence signals I am probing, constraining the neutrino lifetime and increasing the physics output of this work.

% \todo{Not really first due to LBL paper?}

I will also perform a model-independent decoherence search, in which the decoherence effects are modelled as a open quantum system consisting of both the neutrino and its environment, represented as an $SU(3)$ Hilbert space (with the neutrino mass states defined as the basis vectors)~\cite{lindblad1976, Benatti_2000, gago2002study, PhysRevLett.85.1166}. I will fit the coefficients of a generalised decoherence  operator in this formalism, the world's first measurement to probe such a system in it most general form, maximising the sensitivity of the analysis to decoherence from any source. I will investigate the use of Markov Chain Monte Carlo (MCMC) Bayesian inference to constrain these coefficients, as such methods are more suited to simultaneously fitting many free parameters compared to frequentist minimization methods more commonly employed in neutrino oscillation measurements.

% \todo{Mention that limiting decoherence value has power to discriminate between models}

% \textbf{Risk/Gain:} This generalised decoherence search will feature many free parameters in the fit, a major computational challenge for the frequentist \textit{minimisation} algorithms used in most oscillation analyses. Should this prove untenable, I will instead employ Bayesian Markov Chain Monte Carlo (MCMC) methods which have been shown to perform better in many parameter fits. This will require a significant time investment implementing these methods in my analysis software framework\todo{Probably drop this - boring}.

There is also an exciting synergy between the searches proposed in this work. A frequent prediction in quantum gravity phenomenology is that $CPT$-V manifests as differences between neutrino and antineutrino decoherence effects~\cite{Mavromatos_2009, Barenboim:2004wu, Carrasco:2018sca, Buoninfante:2020iyr, Capolupo:2020myw}. This hypothesis has never been experimentally tested, and I will perform the world's first experimental test of $CPT$-V decoherence in this project (having recently demonstrated the feasibility of detecting such signals in IceCube) by fitting certain non-zero off-diagonal matrix elements in the generalised decoherence operator and exploiting the (anti)neutrino separation methods from this project, yielding the prospect of detecting $CPT$-V even if the neutrino-antineutrino oscillation asymmetry effects discussed above prove immeasurably small.

% \todo{More specific at what models can be rejected, e.g. VBH ones. Also mention that $E^2$ is motivated by string theory (add to figure caption too)}

This work will be by far the most sensitive and comprehensive search for energy-suppressed neutrino decoherence ever performed. These results will achieve sensitivity to the naturally expected scale of quantum gravity effects for $\nu$-VBH interactions even up to $E^3$ energy suppression, giving genuine hope of the first quantum gravity signal detection, a truly revolutionary result. A null result in these models will reject all but the most energy-suppressed Planck scale decoherence scenarios, or indicate that the $\nu$-VBH mean free path is much larger than the `natural' prediction. Either way these results will be invaluable in informing the theoretical development of quantum gravity. For the publication of the results I will target the high impact journal \textit{Nature} since it is guaranteed to either detect or rule out the natural Planck scale expectation for some models. I may also split the multiple scenarios tested into separate publications. \\

% The impact of a signal detection would be revolutionary, giving one of very few experimental signatures currently known of physics beyond the Standard Model. Follow-up would include testing these signals in other experiments (such as next-generation atmospheric neutrino experiments such as ORCA, HyperKamiokande and the Indian Neutrino Observatory, or the DUNE accelerator experiment), or indeed in non-neutrino experiments, and would likely result in a slew of new theoretical models to be compared to the experimental data. \\



\subsection{Network}

In addition to the aforementioned collaborations, the phenomenological aspects of this project will benefit from the theoretical expertise of my colleagues Assistant Professors Markus Ahlers and Mauricio Bustamante in the NBI astroparticle theory group, who have already provided invaluable assistance in my work developing neutrino decoherence models. I will also invite quantum gravity experts to NBI to give seminars and collaborate on phenomenological developments (including the aforementioned workshop).

This research will also benefit from my strong collaborations with other international IceCube groups (Europe, US, Japan), established during the numerous collaborative projects I have worked on over the last four years including the latest generation of oscillation analyses and the IceCube Upgrade design studies, as well as in-person collaboration meetings twice per year. I will utilise a number of developments by my collaborators in this project (including TeV scale neutrino reconstruction methods and modelling of the ice in the detector), and the outputs of this project (such as detector simulations, neutrino-antineutrino separation and unified event sample) will also be used in a host of new IceCube measurements by my collaborators over the coming decade. \\


% \todo{Outlook?}

% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------

% \newpage

\vspace{0.3cm}

%\begin{multicols}{2}
\bibliography{references}
%\end{multicols}

\end{document}